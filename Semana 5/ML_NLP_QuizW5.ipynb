{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2dvVvls7dR3"
   },
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFD8i1b97dR5"
   },
   "source": [
    "# Similitud y normalización de textos\n",
    "\n",
    "En este notebook aprenderá a calcular la similitud entre diferentes textos y a normalizarlos usando sklearn y [nltk](https://www.nltk.org/).\n",
    "\n",
    "Este notebook tiene una licencia de [Creative Commons Attribution-ShareAlike 3.0 Unported License](http://creativecommons.org/licenses/by-sa/3.0/deed.en_US). Un agradecimiento especial para [\n",
    "Adrien sieg](https://medium.com/@adriensieg/text-similarities-da019229c894)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxPShVQq7dR6"
   },
   "source": [
    "## Instrucciones Generales\n",
    "\n",
    "La similitud y normalización de textos son tecnicas del procesamiento de lenguaje natural. Mientras que la similitud permite identificar que tan similares son un par de textos, la normalización permite convertir una palabra en su forma más básica.\n",
    "\n",
    "Este notebook esta compuesto por dos secciones. En la primera secciónn, usted beberá a obtener la similitud entre dos textos usando diferentes métricas. En la segunda parte, normalizará el texto del set de noticias populares de UCI, eliminando stopwords y haciedo stemming y lematización. Para conocer más detalles de la base, puede ingresar al siguiente [vínculo](https://archive.ics.uci.edu/ml/datasets/online+news+popularity#).\n",
    "   \n",
    "Para realizar la actividad, solo siga las indicaciones asociadas a cada celda del notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-WrGkB-7dR6",
    "outputId": "049e7ffb-3023-4c9c-9eec-d2056e86ce2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.5 (main, Apr 11 2025, 22:11:19) [Clang 17.0.0 (clang-1700.0.13.3)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5WtbRM1K7dR8"
   },
   "outputs": [],
   "source": [
    "#pip install numpy==2.0.2 tensorflow==2.19.0 scikit-learn==1.6.1 scipy==1.13.1 nltk==3.9.1 pandas==2.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3kJcPNAE7dR8"
   },
   "outputs": [],
   "source": [
    "#pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rqCNIoC77dR9"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XbdYNHT7dR9"
   },
   "source": [
    "## Similitud de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1QSSr6n7dR9"
   },
   "source": [
    "### Similitud de Jaccard\n",
    "La similitud de Jaccard se define como el tamaño de la intersección dividido por el tamaño de la unión de dos conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vRao6Vkj7dR-"
   },
   "outputs": [],
   "source": [
    "# Definición función de similitud de Jaccard que recibe como parámetros dos textos y retorna su similitud\n",
    "def jaccard_similarity(str1, str2):\n",
    "    set1 = set(str1.lower().split())\n",
    "    set2 = set(str2.lower().split())\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return len(intersection) / len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TFSZV5Pi7dR_"
   },
   "outputs": [],
   "source": [
    "# Definición de oraciones para calculo de similitud\n",
    "s1 = \"Una IA pretende imitar la mente humana en el mundo digital\"\n",
    "s2 = \"La imaginación humana es el único límite para una IA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cXOjGBt_7dR_",
    "outputId": "4925ced6-3665-4042-f851-2564728279ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impresión de la similitud de Jaccard entre las dos frases\n",
    "jaccard_similarity(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pz4XyVK7dSA"
   },
   "source": [
    "### Similitud de coseno\n",
    "\n",
    "La similitud del coseno calcula la similitud midiendo el coseno del ángulo entre dos vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9UkpH8z87dSA"
   },
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abl2Lbxu7dSB"
   },
   "source": [
    "#### Similitud de coseno CountVectorizer\n",
    "Al vectorizar con CountVectorizer, este tiene la limitación que palabras de un carácter no se consideran dentro del vocabulario, por ejemplo las palabras 'a' e 'y'. Con esto se tiene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yrLS1KJF7dSB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4622501635210243\n"
     ]
    }
   ],
   "source": [
    "# Definición función de similitud de Coseno que recibe como parámetros dos textos y retorna su similitud\n",
    "def cosine_distance_countVectorizer(s1, s2):\n",
    "\n",
    "    # Uso de CountVectorizer para obtener vectores de una frase\n",
    "    vect = CountVectorizer(binary=True)\n",
    "    X_dtm = vect.fit_transform([s1, s2]).toarray()\n",
    "\n",
    "    return 1-cosine(X_dtm[0],X_dtm[1])\n",
    "\n",
    "str1 = \"El preprocesamiento de texto es importante para los modelos de NLP\"\n",
    "str2 = \"El NLP es importante para diferentes problemas en organizaciones\"\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform([str1, str2])\n",
    "similarity = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6sxtbbsd7dSC"
   },
   "source": [
    "#### Similitud de coseno manual\n",
    "Al realizar la creación los vectores de la frase manualmente se garantiza que se consideran todas las palabras. Con esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XJkSMylO7dSC"
   },
   "outputs": [],
   "source": [
    "def obtener_vectores(union, str1, str2):\n",
    "\n",
    "    s1_l = []\n",
    "    s2_l = []\n",
    "\n",
    "    for palabra in union:\n",
    "        if palabra in str1.split():\n",
    "            s1_l.append(1)\n",
    "        else:\n",
    "            s1_l.append(0)\n",
    "\n",
    "        if palabra in str2.split():\n",
    "            s2_l.append(1)\n",
    "        else:\n",
    "            s2_l.append(0)\n",
    "\n",
    "    return s1_l, s2_l\n",
    "\n",
    "# Definición función de similitud de Coseno que recibe como parámetros dos textos y retorna su similitud\n",
    "def cosine_distance_manual(str1, str2):\n",
    "\n",
    "    union = list(set(str1.split()).union(set(str2.split())))\n",
    "\n",
    "    s1_v, s2_v = obtener_vectores(union, str1, str2)\n",
    "\n",
    "    return 1-cosine(s1_v, s2_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5270462766947299)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impresión de la similitud de coseno entre las dos frases definidas anteriormente\n",
    "cosine_distance_manual(str1, str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6935020,
     "sourceId": 11121148,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "name": "_merged"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
